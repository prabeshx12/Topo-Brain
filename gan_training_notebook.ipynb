{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5826243e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CELL 1: Environment Setup and GPU Check\n",
    "# ============================================================================\n",
    "import torch\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"TOPO-BRAIN GAN TRAINING - ENVIRONMENT SETUP\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Check GPU\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"‚úì GPU Available: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"  Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "    device = 'cuda'\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No GPU available, using CPU (training will be slow!)\")\n",
    "    device = 'cpu'\n",
    "\n",
    "# Kaggle/Colab detection\n",
    "IS_KAGGLE = Path('/kaggle/input').exists()\n",
    "IS_COLAB = Path('/content').exists()\n",
    "\n",
    "if IS_KAGGLE:\n",
    "    print(\"\\n‚úì Running on Kaggle\")\n",
    "    BASE_DIR = Path('/kaggle/working')\n",
    "elif IS_COLAB:\n",
    "    print(\"\\n‚úì Running on Google Colab\")\n",
    "    BASE_DIR = Path('/content')\n",
    "else:\n",
    "    print(\"\\n‚úì Running locally\")\n",
    "    BASE_DIR = Path.cwd()\n",
    "\n",
    "print(f\"\\nBase directory: {BASE_DIR}\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f52703c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CELL 2: Install Dependencies\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"INSTALLING DEPENDENCIES\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "!pip install -q monai nibabel matplotlib tqdm scikit-image scikit-learn tensorboard\n",
    "\n",
    "print(\"‚úì Core dependencies installed\")\n",
    "print(\"‚úì MONAI, NiBabel, Matplotlib, TensorBoard ready\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "001be2bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CELL 3: Clone Repository\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"CLONING TOPO-BRAIN REPOSITORY\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "os.chdir(BASE_DIR)\n",
    "\n",
    "# Clone if not already present\n",
    "if not (BASE_DIR / 'Topo-Brain').exists():\n",
    "    !git clone https://github.com/prabeshx12/Topo-Brain.git\n",
    "    print(\"‚úì Repository cloned\")\n",
    "else:\n",
    "    print(\"‚úì Repository already exists\")\n",
    "\n",
    "os.chdir(BASE_DIR / 'Topo-Brain')\n",
    "sys.path.insert(0, str(BASE_DIR / 'Topo-Brain'))\n",
    "\n",
    "print(f\"\\n‚úì Working directory: {Path.cwd()}\")\n",
    "print(\"‚úì Python path updated\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac76d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CELL 4: Setup Output Directories\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"CREATING OUTPUT DIRECTORIES\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Create all necessary directories\n",
    "DIRS = {\n",
    "    'checkpoints': BASE_DIR / 'gan_checkpoints',\n",
    "    'logs': BASE_DIR / 'gan_logs',\n",
    "    'visualizations': BASE_DIR / 'gan_visualizations',\n",
    "    'cache': BASE_DIR / 'gan_cache',\n",
    "    'final_output': BASE_DIR / 'gan_final_output',\n",
    "}\n",
    "\n",
    "for name, path in DIRS.items():\n",
    "    path.mkdir(parents=True, exist_ok=True)\n",
    "    print(f\"‚úì Created: {name} -> {path}\")\n",
    "\n",
    "print(\"\\n‚úì All directories ready\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bba4610",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CELL 5: Link Preprocessed Data\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"LINKING PREPROCESSED DATA\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# UPDATE THIS PATH to your Kaggle dataset!\n",
    "# After uploading preprocessed data, update this path\n",
    "if IS_KAGGLE:\n",
    "    PREPROCESSED_DATA_PATH = Path('/kaggle/input/unc-paired-3t-7t-preprocessed/')\n",
    "    # Alternative: If you ran preprocessing in same notebook:\n",
    "    # PREPROCESSED_DATA_PATH = Path('/kaggle/working/preprocessed_no_n4/')\n",
    "else:\n",
    "    PREPROCESSED_DATA_PATH = Path('./preprocessed')  # Local path\n",
    "\n",
    "print(f\"Preprocessed data path: {PREPROCESSED_DATA_PATH}\")\n",
    "\n",
    "# Verify data exists\n",
    "if PREPROCESSED_DATA_PATH.exists():\n",
    "    print(f\"‚úì Found preprocessed data directory\")\n",
    "    \n",
    "    # Count files\n",
    "    nifti_files = list(PREPROCESSED_DATA_PATH.rglob(\"*_preprocessed.nii.gz\"))\n",
    "    print(f\"‚úì Total preprocessed volumes: {len(nifti_files)}\")\n",
    "    \n",
    "    # Show structure\n",
    "    subjects = sorted([d.name for d in PREPROCESSED_DATA_PATH.iterdir() \n",
    "                      if d.is_dir() and d.name.startswith('sub-')])\n",
    "    print(f\"‚úì Found {len(subjects)} subjects: {subjects}\")\n",
    "    \n",
    "    # Show sample files\n",
    "    print(\"\\nüìÑ Sample files:\")\n",
    "    for f in sorted(nifti_files)[:5]:\n",
    "        print(f\"   {f.name}\")\n",
    "else:\n",
    "    print(\"‚ùå PREPROCESSED DATA NOT FOUND!\")\n",
    "    print(\"\\nüëâ TO FIX:\")\n",
    "    print(\"   1. Upload preprocessed data as Kaggle Dataset\")\n",
    "    print(\"   2. Or run preprocessing notebook first\")\n",
    "    print(\"   3. Update PREPROCESSED_DATA_PATH in this cell\")\n",
    "    raise FileNotFoundError(f\"Preprocessed data not found at {PREPROCESSED_DATA_PATH}\")\n",
    "\n",
    "print(\"\\n‚úì Data validation complete\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e07dfb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CELL 6: Import Models and Utilities\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"IMPORTING MODELS AND UTILITIES\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import random\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Import your models\n",
    "try:\n",
    "    from models.generator_unet3d import UNet3DGenerator\n",
    "    from models.discriminator_patchgan3d import PatchGANDiscriminator3D\n",
    "    print(\"‚úì Imported models from repository\")\n",
    "except ImportError as e:\n",
    "    print(f\"‚ö†Ô∏è Import error: {e}\")\n",
    "    print(\"‚ö†Ô∏è Will use simplified models\")\n",
    "    \n",
    "    # Simplified fallback models (basic versions)\n",
    "    class UNet3DGenerator(nn.Module):\n",
    "        def __init__(self, in_channels=1, out_channels=1, base_features=32):\n",
    "            super().__init__()\n",
    "            # Simplified U-Net - replace with your actual implementation\n",
    "            self.encoder = nn.Sequential(\n",
    "                nn.Conv3d(in_channels, base_features, 3, padding=1),\n",
    "                nn.InstanceNorm3d(base_features),\n",
    "                nn.ReLU(inplace=True),\n",
    "            )\n",
    "            self.decoder = nn.Sequential(\n",
    "                nn.Conv3d(base_features, out_channels, 3, padding=1),\n",
    "                nn.Tanh(),\n",
    "            )\n",
    "        \n",
    "        def forward(self, x):\n",
    "            features = self.encoder(x)\n",
    "            output = self.decoder(features)\n",
    "            return output\n",
    "    \n",
    "    class PatchGANDiscriminator3D(nn.Module):\n",
    "        def __init__(self, in_channels=1, base_features=64):\n",
    "            super().__init__()\n",
    "            # Simplified PatchGAN - replace with your actual implementation\n",
    "            self.model = nn.Sequential(\n",
    "                nn.Conv3d(in_channels, base_features, 4, 2, 1),\n",
    "                nn.LeakyReLU(0.2, inplace=True),\n",
    "                nn.Conv3d(base_features, base_features*2, 4, 2, 1),\n",
    "                nn.InstanceNorm3d(base_features*2),\n",
    "                nn.LeakyReLU(0.2, inplace=True),\n",
    "                nn.Conv3d(base_features*2, 1, 4, 1, 1),\n",
    "            )\n",
    "        \n",
    "        def forward(self, x):\n",
    "            return self.model(x)\n",
    "\n",
    "print(\"‚úì Models ready\")\n",
    "print(\"‚úì PyTorch imports complete\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f389a6ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CELL 7: Dataset Class for Paired 3T-7T Data\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"CREATING DATASET CLASS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "class Paired3T7TDataset(Dataset):\n",
    "    \"\"\"\n",
    "    PyTorch Dataset for paired 3T-7T MRI volumes.\n",
    "    Extracts random 3D patches for training.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        data_pairs,\n",
    "        patch_size=(64, 64, 64),\n",
    "        num_patches_per_volume=10,\n",
    "        transform=None,\n",
    "        cache_data=False,\n",
    "    ):\n",
    "        self.data_pairs = data_pairs\n",
    "        self.patch_size = patch_size\n",
    "        self.num_patches_per_volume = num_patches_per_volume\n",
    "        self.transform = transform\n",
    "        self.cache_data = cache_data\n",
    "        self.cache = {}\n",
    "        \n",
    "        self.total_patches = len(data_pairs) * num_patches_per_volume\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.total_patches\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # Determine which volume pair and patch number\n",
    "        pair_idx = idx // self.num_patches_per_volume\n",
    "        pair = self.data_pairs[pair_idx]\n",
    "        \n",
    "        # Load or retrieve from cache\n",
    "        if self.cache_data and pair_idx in self.cache:\n",
    "            vol_3t, vol_7t = self.cache[pair_idx]\n",
    "        else:\n",
    "            vol_3t = nib.load(pair['input_3t']).get_fdata().astype(np.float32)\n",
    "            vol_7t = nib.load(pair['target_7t']).get_fdata().astype(np.float32)\n",
    "            \n",
    "            if self.cache_data:\n",
    "                self.cache[pair_idx] = (vol_3t, vol_7t)\n",
    "        \n",
    "        # Extract random patch\n",
    "        patch_3t, patch_7t = self._extract_random_patch(vol_3t, vol_7t)\n",
    "        \n",
    "        # To tensor and add channel dimension\n",
    "        patch_3t = torch.from_numpy(patch_3t[None, ...])  # [1, D, H, W]\n",
    "        patch_7t = torch.from_numpy(patch_7t[None, ...])\n",
    "        \n",
    "        # Apply transforms if any\n",
    "        if self.transform:\n",
    "            patch_3t = self.transform(patch_3t)\n",
    "            patch_7t = self.transform(patch_7t)\n",
    "        \n",
    "        return {\n",
    "            'input_3t': patch_3t,\n",
    "            'target_7t': patch_7t,\n",
    "            'subject': pair.get('subject', 'unknown'),\n",
    "        }\n",
    "    \n",
    "    def _extract_random_patch(self, vol_3t, vol_7t):\n",
    "        \"\"\"Extract matching random patch from both volumes.\"\"\"\n",
    "        d, h, w = vol_3t.shape\n",
    "        pd, ph, pw = self.patch_size\n",
    "        \n",
    "        # Random starting coordinates\n",
    "        start_d = random.randint(0, max(0, d - pd))\n",
    "        start_h = random.randint(0, max(0, h - ph))\n",
    "        start_w = random.randint(0, max(0, w - pw))\n",
    "        \n",
    "        # Extract patches\n",
    "        patch_3t = vol_3t[start_d:start_d+pd, start_h:start_h+ph, start_w:start_w+pw]\n",
    "        patch_7t = vol_7t[start_d:start_d+pd, start_h:start_h+ph, start_w:start_w+pw]\n",
    "        \n",
    "        # Pad if necessary\n",
    "        if patch_3t.shape != self.patch_size:\n",
    "            patch_3t = self._pad_to_size(patch_3t, self.patch_size)\n",
    "            patch_7t = self._pad_to_size(patch_7t, self.patch_size)\n",
    "        \n",
    "        return patch_3t, patch_7t\n",
    "    \n",
    "    def _pad_to_size(self, volume, target_size):\n",
    "        \"\"\"Pad volume to target size.\"\"\"\n",
    "        pad_width = []\n",
    "        for i in range(3):\n",
    "            diff = target_size[i] - volume.shape[i]\n",
    "            pad_before = diff // 2\n",
    "            pad_after = diff - pad_before\n",
    "            pad_width.append((pad_before, pad_after))\n",
    "        \n",
    "        return np.pad(volume, pad_width, mode='constant', constant_values=0)\n",
    "\n",
    "print(\"‚úì Dataset class defined\")\n",
    "print(\"‚úì Supports random patch extraction\")\n",
    "print(\"‚úì Optional data caching\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd1d740c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CELL 8: Create Data Pairs and Splits (Multi-Modal Support)\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"CREATING 3T-7T DATA PAIRS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "def create_paired_data_list(preprocessed_dir, modalities):\n",
    "    \"\"\"\n",
    "    Create list of paired 3T-7T volumes.\n",
    "    Supports single modality (str) or multiple (list).\n",
    "    Assumes: ses-1 = 3T, ses-2 = 7T\n",
    "    \"\"\"\n",
    "    preprocessed_dir = Path(preprocessed_dir)\n",
    "    \n",
    "    # Handle both string and list inputs\n",
    "    if isinstance(modalities, str):\n",
    "        modalities = [modalities]\n",
    "    \n",
    "    all_pairs = []\n",
    "    \n",
    "    for modality in modalities:\n",
    "        print(f\"üîç Searching for {modality} pairs...\")\n",
    "        \n",
    "        # Group files by subject\n",
    "        files_by_subject = {}\n",
    "        for file in preprocessed_dir.rglob(f\"*{modality}_preprocessed.nii.gz\"):\n",
    "            # Parse: sub-01_ses-1_T1w_preprocessed.nii.gz\n",
    "            parts = file.stem.replace('_preprocessed', '').split('_')\n",
    "            subject = parts[0]  # sub-01\n",
    "            session = parts[1]  # ses-1 or ses-2\n",
    "            \n",
    "            if subject not in files_by_subject:\n",
    "                files_by_subject[subject] = {}\n",
    "            files_by_subject[subject][session] = file\n",
    "        \n",
    "        # Create pairs\n",
    "        for subject, sessions in files_by_subject.items():\n",
    "            if 'ses-1' in sessions and 'ses-2' in sessions:\n",
    "                all_pairs.append({\n",
    "                    'subject': subject,\n",
    "                    'input_3t': str(sessions['ses-1']),\n",
    "                    'target_7t': str(sessions['ses-2']),\n",
    "                    'modality': modality,\n",
    "                })\n",
    "        \n",
    "        print(f\"   ‚úì Found {sum(1 for p in all_pairs if p['modality'] == modality)} {modality} pairs\")\n",
    "    \n",
    "    return all_pairs\n",
    "\n",
    "# Configuration\n",
    "# ============================================\n",
    "# CHANGE THIS LINE to train on both modalities:\n",
    "# ============================================\n",
    "MODALITIES = ['T1w', 'T2w']  # ‚Üê Train on BOTH!\n",
    "# OR use single: MODALITIES = 'T1w'  # ‚Üê Train on T1w only\n",
    "\n",
    "TRAIN_RATIO = 0.6\n",
    "VAL_RATIO = 0.2\n",
    "TEST_RATIO = 0.2\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "# Set seed for reproducibility\n",
    "random.seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "\n",
    "# Create pairs (works with both single and multiple modalities)\n",
    "if isinstance(MODALITIES, str):\n",
    "    print(f\"üîç Searching for {MODALITIES} pairs...\")\n",
    "else:\n",
    "    print(f\"üîç Searching for {MODALITIES} pairs...\")\n",
    "\n",
    "all_pairs = create_paired_data_list(PREPROCESSED_DATA_PATH, MODALITIES)\n",
    "print(f\"‚úì Total: {len(all_pairs)} paired volumes\")\n",
    "\n",
    "# Show breakdown\n",
    "if isinstance(MODALITIES, list):\n",
    "    for mod in MODALITIES:\n",
    "        n = sum(1 for p in all_pairs if p['modality'] == mod)\n",
    "        print(f\"   ‚Ä¢ {mod}: {n} pairs\")\n",
    "\n",
    "# Patient-level split (NO DATA LEAKAGE!)\n",
    "subjects = list(set([p['subject'] for p in all_pairs]))\n",
    "print(f\"‚úì Total subjects: {len(subjects)}\")\n",
    "\n",
    "random.shuffle(subjects)\n",
    "\n",
    "n_train = int(len(subjects) * TRAIN_RATIO)\n",
    "n_val = int(len(subjects) * VAL_RATIO)\n",
    "\n",
    "train_subjects = subjects[:n_train]\n",
    "val_subjects = subjects[n_train:n_train + n_val]\n",
    "test_subjects = subjects[n_train + n_val:]\n",
    "\n",
    "# Create splits (includes all modalities for each subject)\n",
    "train_pairs = [p for p in all_pairs if p['subject'] in train_subjects]\n",
    "val_pairs = [p for p in all_pairs if p['subject'] in val_subjects]\n",
    "test_pairs = [p for p in all_pairs if p['subject'] in test_subjects]\n",
    "\n",
    "print(f\"\\nüìä Data Splits:\")\n",
    "print(f\"   Train: {len(train_pairs)} pairs from {len(train_subjects)} subjects\")\n",
    "print(f\"   Val:   {len(val_pairs)} pairs from {len(val_subjects)} subjects\")\n",
    "print(f\"   Test:  {len(test_pairs)} pairs from {len(test_subjects)} subjects\")\n",
    "\n",
    "print(f\"\\nüìã Train subjects: {train_subjects}\")\n",
    "print(f\"üìã Val subjects:   {val_subjects}\")\n",
    "print(f\"üìã Test subjects:  {test_subjects}\")\n",
    "\n",
    "# Save split info\n",
    "split_info = {\n",
    "    'train_subjects': train_subjects,\n",
    "    'val_subjects': val_subjects,\n",
    "    'test_subjects': test_subjects,\n",
    "    'train_pairs': len(train_pairs),\n",
    "    'val_pairs': len(val_pairs),\n",
    "    'test_pairs': len(test_pairs),\n",
    "    'modalities': MODALITIES if isinstance(MODALITIES, list) else [MODALITIES],\n",
    "    'random_seed': RANDOM_SEED,\n",
    "    'created': datetime.now().isoformat(),\n",
    "}\n",
    "\n",
    "with open(DIRS['cache'] / 'data_split.json', 'w') as f:\n",
    "    json.dump(split_info, f, indent=2)\n",
    "\n",
    "print(f\"\\n‚úì Split info saved to: {DIRS['cache'] / 'data_split.json'}\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "527bb936",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CELL 9: Create DataLoaders\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"CREATING PYTORCH DATALOADERS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Hyperparameters\n",
    "BATCH_SIZE = 2              # Reduce to 1 if Out-Of-Memory\n",
    "PATCH_SIZE = (64, 64, 64)   # Reduce to (32, 32, 32) if OOM\n",
    "NUM_PATCHES_PER_VOLUME = 10 # Patches per volume per epoch\n",
    "NUM_WORKERS = 2             # Parallel data loading\n",
    "\n",
    "print(f\"‚öôÔ∏è Configuration:\")\n",
    "print(f\"   Batch size: {BATCH_SIZE}\")\n",
    "print(f\"   Patch size: {PATCH_SIZE}\")\n",
    "print(f\"   Patches per volume: {NUM_PATCHES_PER_VOLUME}\")\n",
    "print(f\"   Num workers: {NUM_WORKERS}\")\n",
    "\n",
    "# Create datasets\n",
    "print(f\"\\nüì¶ Creating datasets...\")\n",
    "\n",
    "train_dataset = Paired3T7TDataset(\n",
    "    data_pairs=train_pairs,\n",
    "    patch_size=PATCH_SIZE,\n",
    "    num_patches_per_volume=NUM_PATCHES_PER_VOLUME,\n",
    "    cache_data=False,  # Set True if enough RAM\n",
    ")\n",
    "\n",
    "val_dataset = Paired3T7TDataset(\n",
    "    data_pairs=val_pairs,\n",
    "    patch_size=PATCH_SIZE,\n",
    "    num_patches_per_volume=5,  # Fewer for validation\n",
    "    cache_data=False,\n",
    ")\n",
    "\n",
    "# Create loaders\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    pin_memory=True if device == 'cuda' else False,\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    pin_memory=True if device == 'cuda' else False,\n",
    ")\n",
    "\n",
    "print(f\"\\n‚úì Train loader: {len(train_loader)} batches\")\n",
    "print(f\"‚úì Val loader:   {len(val_loader)} batches\")\n",
    "\n",
    "# Test loading\n",
    "print(f\"\\nüß™ Testing data loading...\")\n",
    "test_batch = next(iter(train_loader))\n",
    "print(f\"‚úì Batch loaded successfully!\")\n",
    "print(f\"   Input 3T shape:  {test_batch['input_3t'].shape}\")\n",
    "print(f\"   Target 7T shape: {test_batch['target_7t'].shape}\")\n",
    "print(f\"   Subjects: {test_batch['subject']}\")\n",
    "\n",
    "print(\"\\n‚úì DataLoaders ready for training\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38adb2c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CELL 10: Initialize Models and Optimizers\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"INITIALIZING MODELS AND OPTIMIZERS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Model parameters\n",
    "BASE_FEATURES_G = 32  # Generator base features\n",
    "BASE_FEATURES_D = 64  # Discriminator base features\n",
    "\n",
    "print(f\"üèóÔ∏è Creating models...\")\n",
    "\n",
    "# Generator: 3D U-Net\n",
    "generator = UNet3DGenerator(\n",
    "    in_channels=1,\n",
    "    out_channels=1,\n",
    "    base_features=BASE_FEATURES_G,\n",
    ").to(device)\n",
    "\n",
    "# Discriminator: 3D PatchGAN\n",
    "discriminator = PatchGANDiscriminator3D(\n",
    "    in_channels=1,\n",
    "    base_features=BASE_FEATURES_D,\n",
    ").to(device)\n",
    "\n",
    "# Count parameters\n",
    "n_params_g = sum(p.numel() for p in generator.parameters())\n",
    "n_params_d = sum(p.numel() for p in discriminator.parameters())\n",
    "\n",
    "print(f\"‚úì Generator parameters:     {n_params_g:,}\")\n",
    "print(f\"‚úì Discriminator parameters: {n_params_d:,}\")\n",
    "\n",
    "# Optimizers\n",
    "LR_G = 2e-4\n",
    "LR_D = 2e-4\n",
    "BETA1 = 0.5\n",
    "BETA2 = 0.999\n",
    "\n",
    "optimizer_g = optim.Adam(generator.parameters(), lr=LR_G, betas=(BETA1, BETA2))\n",
    "optimizer_d = optim.Adam(discriminator.parameters(), lr=LR_D, betas=(BETA1, BETA2))\n",
    "\n",
    "print(f\"\\n‚öôÔ∏è Optimizers:\")\n",
    "print(f\"   Generator LR:     {LR_G}\")\n",
    "print(f\"   Discriminator LR: {LR_D}\")\n",
    "\n",
    "# Loss functions\n",
    "criterion_l1 = nn.L1Loss()\n",
    "criterion_adv = nn.MSELoss()  # LSGAN (more stable)\n",
    "\n",
    "# Loss weights\n",
    "LAMBDA_L1 = 100.0   # Weight for L1 reconstruction\n",
    "LAMBDA_ADV = 1.0    # Weight for adversarial loss\n",
    "\n",
    "print(f\"\\nüìä Loss configuration:\")\n",
    "print(f\"   L1 weight:  {LAMBDA_L1}\")\n",
    "print(f\"   Adv weight: {LAMBDA_ADV}\")\n",
    "\n",
    "# Mixed precision training\n",
    "USE_AMP = True if device == 'cuda' else False\n",
    "scaler_g = GradScaler() if USE_AMP else None\n",
    "scaler_d = GradScaler() if USE_AMP else None\n",
    "\n",
    "print(f\"\\n‚ö° Mixed precision: {USE_AMP}\")\n",
    "\n",
    "print(\"\\n‚úì All models and optimizers ready\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93185cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CELL 11: Training Loop\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"STARTING GAN TRAINING\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "import time\n",
    "\n",
    "# Training configuration\n",
    "NUM_EPOCHS = 100\n",
    "SAVE_INTERVAL = 5\n",
    "LOG_INTERVAL = 10\n",
    "\n",
    "# Tracking\n",
    "train_losses_g = []\n",
    "train_losses_d = []\n",
    "val_losses = []\n",
    "best_val_loss = float('inf')\n",
    "\n",
    "print(f\"üöÄ Training Configuration:\")\n",
    "print(f\"   Epochs: {NUM_EPOCHS}\")\n",
    "print(f\"   Device: {device}\")\n",
    "print(f\"   Batch size: {BATCH_SIZE}\")\n",
    "print(f\"   Patch size: {PATCH_SIZE}\")\n",
    "print(f\"   Train batches: {len(train_loader)}\")\n",
    "print(f\"   Val batches: {len(val_loader)}\")\n",
    "print(f\"\\n{'='*70}\\n\")\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for epoch in range(1, NUM_EPOCHS + 1):\n",
    "    epoch_start = time.time()\n",
    "    \n",
    "    # ============ TRAINING PHASE ============\n",
    "    generator.train()\n",
    "    discriminator.train()\n",
    "    \n",
    "    epoch_loss_g = 0.0\n",
    "    epoch_loss_d = 0.0\n",
    "    epoch_loss_l1 = 0.0\n",
    "    epoch_loss_adv = 0.0\n",
    "    \n",
    "    pbar = tqdm(train_loader, desc=f\"Epoch {epoch}/{NUM_EPOCHS}\", leave=False)\n",
    "    \n",
    "    for i, batch in enumerate(pbar):\n",
    "        input_3t = batch['input_3t'].to(device)\n",
    "        target_7t = batch['target_7t'].to(device)\n",
    "        batch_size_current = input_3t.size(0)\n",
    "        \n",
    "        # ===== TRAIN DISCRIMINATOR =====\n",
    "        optimizer_d.zero_grad()\n",
    "        \n",
    "        with autocast(enabled=USE_AMP):\n",
    "            # Generate fake 7T\n",
    "            fake_7t = generator(input_3t)\n",
    "            \n",
    "            # Discriminator predictions\n",
    "            pred_real = discriminator(target_7t)\n",
    "            pred_fake = discriminator(fake_7t.detach())\n",
    "            \n",
    "            # Labels (LSGAN: real=1, fake=0)\n",
    "            real_label = torch.ones_like(pred_real)\n",
    "            fake_label = torch.zeros_like(pred_fake)\n",
    "            \n",
    "            # Discriminator loss\n",
    "            loss_d_real = criterion_adv(pred_real, real_label)\n",
    "            loss_d_fake = criterion_adv(pred_fake, fake_label)\n",
    "            loss_d = 0.5 * (loss_d_real + loss_d_fake)\n",
    "        \n",
    "        if USE_AMP:\n",
    "            scaler_d.scale(loss_d).backward()\n",
    "            scaler_d.step(optimizer_d)\n",
    "            scaler_d.update()\n",
    "        else:\n",
    "            loss_d.backward()\n",
    "            optimizer_d.step()\n",
    "        \n",
    "        # ===== TRAIN GENERATOR =====\n",
    "        optimizer_g.zero_grad()\n",
    "        \n",
    "        with autocast(enabled=USE_AMP):\n",
    "            # Generate fake 7T (fresh forward pass)\n",
    "            fake_7t = generator(input_3t)\n",
    "            \n",
    "            # Adversarial loss (fool discriminator)\n",
    "            pred_fake = discriminator(fake_7t)\n",
    "            loss_adv = criterion_adv(pred_fake, real_label)\n",
    "            \n",
    "            # L1 reconstruction loss\n",
    "            loss_l1 = criterion_l1(fake_7t, target_7t)\n",
    "            \n",
    "            # Total generator loss\n",
    "            loss_g = LAMBDA_ADV * loss_adv + LAMBDA_L1 * loss_l1\n",
    "        \n",
    "        if USE_AMP:\n",
    "            scaler_g.scale(loss_g).backward()\n",
    "            scaler_g.step(optimizer_g)\n",
    "            scaler_g.update()\n",
    "        else:\n",
    "            loss_g.backward()\n",
    "            optimizer_g.step()\n",
    "        \n",
    "        # Track losses\n",
    "        epoch_loss_g += loss_g.item()\n",
    "        epoch_loss_d += loss_d.item()\n",
    "        epoch_loss_l1 += loss_l1.item()\n",
    "        epoch_loss_adv += loss_adv.item()\n",
    "        \n",
    "        # Update progress bar\n",
    "        pbar.set_postfix({\n",
    "            'G': f'{loss_g.item():.3f}',\n",
    "            'D': f'{loss_d.item():.3f}',\n",
    "            'L1': f'{loss_l1.item():.4f}',\n",
    "        })\n",
    "    \n",
    "    # Average losses\n",
    "    avg_loss_g = epoch_loss_g / len(train_loader)\n",
    "    avg_loss_d = epoch_loss_d / len(train_loader)\n",
    "    avg_loss_l1 = epoch_loss_l1 / len(train_loader)\n",
    "    avg_loss_adv = epoch_loss_adv / len(train_loader)\n",
    "    \n",
    "    train_losses_g.append(avg_loss_g)\n",
    "    train_losses_d.append(avg_loss_d)\n",
    "    \n",
    "    # ============ VALIDATION PHASE ============\n",
    "    generator.eval()\n",
    "    val_loss_total = 0.0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            input_3t = batch['input_3t'].to(device)\n",
    "            target_7t = batch['target_7t'].to(device)\n",
    "            \n",
    "            fake_7t = generator(input_3t)\n",
    "            loss = criterion_l1(fake_7t, target_7t)\n",
    "            val_loss_total += loss.item()\n",
    "    \n",
    "    avg_val_loss = val_loss_total / len(val_loader)\n",
    "    val_losses.append(avg_val_loss)\n",
    "    \n",
    "    # ============ LOGGING ============\n",
    "    epoch_time = time.time() - epoch_start\n",
    "    elapsed_total = time.time() - start_time\n",
    "    \n",
    "    print(f\"\\nEpoch {epoch}/{NUM_EPOCHS} ({epoch_time:.1f}s, total: {elapsed_total/60:.1f}m)\")\n",
    "    print(f\"  Train - G: {avg_loss_g:.4f} | D: {avg_loss_d:.4f} | L1: {avg_loss_l1:.4f} | Adv: {avg_loss_adv:.4f}\")\n",
    "    print(f\"  Val   - L1: {avg_val_loss:.4f} | Best: {min(val_losses):.4f}\")\n",
    "    \n",
    "    # ============ SAVE CHECKPOINT ============\n",
    "    if epoch % SAVE_INTERVAL == 0 or avg_val_loss < best_val_loss:\n",
    "        checkpoint = {\n",
    "            'epoch': epoch,\n",
    "            'generator_state_dict': generator.state_dict(),\n",
    "            'discriminator_state_dict': discriminator.state_dict(),\n",
    "            'optimizer_g_state_dict': optimizer_g.state_dict(),\n",
    "            'optimizer_d_state_dict': optimizer_d.state_dict(),\n",
    "            'train_loss_g': train_losses_g,\n",
    "            'train_loss_d': train_losses_d,\n",
    "            'val_losses': val_losses,\n",
    "            'config': {\n",
    "                'batch_size': BATCH_SIZE,\n",
    "                'patch_size': PATCH_SIZE,\n",
    "                'lambda_l1': LAMBDA_L1,\n",
    "                'lambda_adv': LAMBDA_ADV,\n",
    "                'lr_g': LR_G,\n",
    "                'lr_d': LR_D,\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        # Regular checkpoint\n",
    "        if epoch % SAVE_INTERVAL == 0:\n",
    "            checkpoint_path = DIRS['checkpoints'] / f'checkpoint_epoch_{epoch}.pth'\n",
    "            torch.save(checkpoint, checkpoint_path)\n",
    "            print(f\"  üíæ Saved: checkpoint_epoch_{epoch}.pth\")\n",
    "        \n",
    "        # Best model\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            torch.save(checkpoint, DIRS['checkpoints'] / 'best_model.pth')\n",
    "            print(f\"  ‚≠ê NEW BEST MODEL! Val loss: {avg_val_loss:.4f}\")\n",
    "\n",
    "total_time = time.time() - start_time\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"üéâ TRAINING COMPLETE!\")\n",
    "print(f\"   Total time: {total_time/3600:.2f} hours\")\n",
    "print(f\"   Best val loss: {best_val_loss:.4f}\")\n",
    "print(f\"   Final epoch: {NUM_EPOCHS}\")\n",
    "print(f\"{'='*70}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d74f629",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CELL 12: Plot Training Curves\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"VISUALIZING TRAINING PROGRESS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# Plot 1: Generator and Discriminator losses\n",
    "axes[0].plot(train_losses_g, label='Generator', linewidth=2, color='blue')\n",
    "axes[0].plot(train_losses_d, label='Discriminator', linewidth=2, color='red')\n",
    "axes[0].set_xlabel('Epoch', fontsize=12)\n",
    "axes[0].set_ylabel('Loss', fontsize=12)\n",
    "axes[0].set_title('Training Losses (G vs D)', fontsize=14, fontweight='bold')\n",
    "axes[0].legend(fontsize=11)\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: Validation loss\n",
    "axes[1].plot(val_losses, label='Validation L1', color='green', linewidth=2)\n",
    "axes[1].axhline(y=min(val_losses), color='r', linestyle='--', \n",
    "                label=f'Best: {min(val_losses):.4f}', linewidth=1.5)\n",
    "axes[1].set_xlabel('Epoch', fontsize=12)\n",
    "axes[1].set_ylabel('L1 Loss', fontsize=12)\n",
    "axes[1].set_title('Validation Loss', fontsize=14, fontweight='bold')\n",
    "axes[1].legend(fontsize=11)\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 3: Loss ratio (G/D balance)\n",
    "loss_ratio = np.array(train_losses_g) / (np.array(train_losses_d) + 1e-8)\n",
    "axes[2].plot(loss_ratio, label='G/D Ratio', color='purple', linewidth=2)\n",
    "axes[2].axhline(y=1.0, color='r', linestyle='--', label='Balanced (G=D)', linewidth=1.5)\n",
    "axes[2].set_xlabel('Epoch', fontsize=12)\n",
    "axes[2].set_ylabel('Loss Ratio', fontsize=12)\n",
    "axes[2].set_title('Generator/Discriminator Balance', fontsize=14, fontweight='bold')\n",
    "axes[2].legend(fontsize=11)\n",
    "axes[2].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save figure\n",
    "curves_path = DIRS['logs'] / 'training_curves.png'\n",
    "plt.savefig(curves_path, dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\n‚úì Training curves saved to: {curves_path.name}\")\n",
    "print(f\"‚úì Best validation loss: {min(val_losses):.4f} at epoch {np.argmin(val_losses) + 1}\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04473074",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CELL 13: Generate and Visualize Test Samples\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"GENERATING TEST SAMPLES\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Load best model\n",
    "checkpoint = torch.load(DIRS['checkpoints'] / 'best_model.pth', map_location=device)\n",
    "generator.load_state_dict(checkpoint['generator_state_dict'])\n",
    "generator.eval()\n",
    "\n",
    "print(f\"‚úì Loaded best model from epoch {checkpoint['epoch']}\")\n",
    "\n",
    "# Get validation samples\n",
    "val_iter = iter(val_loader)\n",
    "test_batch = next(val_iter)\n",
    "\n",
    "input_3t = test_batch['input_3t'].to(device)\n",
    "target_7t = test_batch['target_7t'].to(device)\n",
    "subjects = test_batch['subject']\n",
    "\n",
    "# Generate\n",
    "print(f\"‚úì Generating 7T images from 3T...\")\n",
    "with torch.no_grad():\n",
    "    fake_7t = generator(input_3t)\n",
    "\n",
    "print(f\"‚úì Generated {fake_7t.shape[0]} samples\")\n",
    "\n",
    "# Visualization function\n",
    "def visualize_comparison(input_3t, fake_7t, target_7t, subject, save_dir):\n",
    "    \"\"\"Compare 3T input, Generated 7T, and Real 7T\"\"\"\n",
    "    # Move to CPU and get numpy arrays\n",
    "    input_np = input_3t[0, 0].cpu().numpy()\n",
    "    fake_np = fake_7t[0, 0].cpu().numpy()\n",
    "    target_np = target_7t[0, 0].cpu().numpy()\n",
    "    \n",
    "    # Get middle slices\n",
    "    d, h, w = input_np.shape\n",
    "    slice_idx = {\n",
    "        'axial': d // 2,\n",
    "        'coronal': h // 2,\n",
    "        'sagittal': w // 2,\n",
    "    }\n",
    "    \n",
    "    # Create figure\n",
    "    fig, axes = plt.subplots(3, 3, figsize=(15, 15))\n",
    "    fig.suptitle(f'Subject: {subject}', fontsize=16, fontweight='bold', y=0.98)\n",
    "    \n",
    "    titles = ['3T Input', 'Generated 7T', 'Real 7T']\n",
    "    \n",
    "    for col, (data, title) in enumerate(zip([input_np, fake_np, target_np], titles)):\n",
    "        # Axial slice\n",
    "        axes[0, col].imshow(data[slice_idx['axial'], :, :], cmap='gray', \n",
    "                           vmin=-3, vmax=3)\n",
    "        axes[0, col].set_title(f'{title} - Axial', fontsize=12, fontweight='bold')\n",
    "        axes[0, col].axis('off')\n",
    "        \n",
    "        # Coronal slice\n",
    "        axes[1, col].imshow(data[:, slice_idx['coronal'], :], cmap='gray',\n",
    "                           vmin=-3, vmax=3)\n",
    "        axes[1, col].set_title(f'{title} - Coronal', fontsize=12, fontweight='bold')\n",
    "        axes[1, col].axis('off')\n",
    "        \n",
    "        # Sagittal slice\n",
    "        axes[2, col].imshow(data[:, :, slice_idx['sagittal']], cmap='gray',\n",
    "                           vmin=-3, vmax=3)\n",
    "        axes[2, col].set_title(f'{title} - Sagittal', fontsize=12, fontweight='bold')\n",
    "        axes[2, col].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save\n",
    "    save_path = save_dir / f'generation_{subject}.png'\n",
    "    plt.savefig(save_path, dpi=150, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    return save_path\n",
    "\n",
    "# Visualize all samples in batch\n",
    "print(f\"\\nüìä Creating visualizations...\")\n",
    "for i in range(input_3t.size(0)):\n",
    "    vis_path = visualize_comparison(\n",
    "        input_3t[i:i+1], \n",
    "        fake_7t[i:i+1], \n",
    "        target_7t[i:i+1],\n",
    "        subjects[i],\n",
    "        DIRS['visualizations']\n",
    "    )\n",
    "    print(f\"‚úì Saved: {vis_path.name}\")\n",
    "\n",
    "# Display one example\n",
    "example_path = DIRS['visualizations'] / f'generation_{subjects[0]}.png'\n",
    "if example_path.exists():\n",
    "    from IPython.display import Image, display\n",
    "    display(Image(filename=str(example_path)))\n",
    "\n",
    "print(\"\\n‚úì All visualizations complete\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d0805c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CELL 14: Compute Quantitative Metrics (PSNR, SSIM)\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"COMPUTING QUANTITATIVE METRICS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "\n",
    "def compute_metrics(fake, real):\n",
    "    \"\"\"Compute PSNR and SSIM between generated and real images.\"\"\"\n",
    "    fake_np = fake.cpu().numpy()\n",
    "    real_np = real.cpu().numpy()\n",
    "    \n",
    "    # Normalize to [0, 1] for metrics\n",
    "    fake_norm = (fake_np - fake_np.min()) / (fake_np.max() - fake_np.min() + 1e-8)\n",
    "    real_norm = (real_np - real_np.min()) / (real_np.max() - real_np.min() + 1e-8)\n",
    "    \n",
    "    # Compute metrics\n",
    "    psnr_val = psnr(real_norm, fake_norm, data_range=1.0)\n",
    "    ssim_val = ssim(real_norm, fake_norm, data_range=1.0)\n",
    "    \n",
    "    return psnr_val, ssim_val\n",
    "\n",
    "# Compute on full validation set\n",
    "print(\"üìä Computing metrics on validation set...\")\n",
    "all_psnr = []\n",
    "all_ssim = []\n",
    "\n",
    "generator.eval()\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(val_loader, desc=\"Computing metrics\"):\n",
    "        input_3t = batch['input_3t'].to(device)\n",
    "        target_7t = batch['target_7t'].to(device)\n",
    "        \n",
    "        fake_7t = generator(input_3t)\n",
    "        \n",
    "        # Compute for each sample in batch\n",
    "        for i in range(input_3t.size(0)):\n",
    "            psnr_val, ssim_val = compute_metrics(fake_7t[i, 0], target_7t[i, 0])\n",
    "            all_psnr.append(psnr_val)\n",
    "            all_ssim.append(ssim_val)\n",
    "\n",
    "# Compute statistics\n",
    "psnr_mean = np.mean(all_psnr)\n",
    "psnr_std = np.std(all_psnr)\n",
    "ssim_mean = np.mean(all_ssim)\n",
    "ssim_std = np.std(all_ssim)\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"üìä QUANTITATIVE RESULTS:\")\n",
    "print(f\"{'='*70}\")\n",
    "print(f\"  PSNR: {psnr_mean:.2f} ¬± {psnr_std:.2f} dB\")\n",
    "print(f\"       Min: {np.min(all_psnr):.2f} dB\")\n",
    "print(f\"       Max: {np.max(all_psnr):.2f} dB\")\n",
    "print(f\"\\n  SSIM: {ssim_mean:.4f} ¬± {ssim_std:.4f}\")\n",
    "print(f\"       Min: {np.min(all_ssim):.4f}\")\n",
    "print(f\"       Max: {np.max(all_ssim):.4f}\")\n",
    "print(f\"{'='*70}\")\n",
    "\n",
    "# Save metrics\n",
    "metrics_summary = {\n",
    "    'validation_metrics': {\n",
    "        'psnr_mean': float(psnr_mean),\n",
    "        'psnr_std': float(psnr_std),\n",
    "        'psnr_min': float(np.min(all_psnr)),\n",
    "        'psnr_max': float(np.max(all_psnr)),\n",
    "        'ssim_mean': float(ssim_mean),\n",
    "        'ssim_std': float(ssim_std),\n",
    "        'ssim_min': float(np.min(all_ssim)),\n",
    "        'ssim_max': float(np.max(all_ssim)),\n",
    "    },\n",
    "    'training_info': {\n",
    "        'num_epochs': NUM_EPOCHS,\n",
    "        'best_val_loss': float(best_val_loss),\n",
    "        'best_epoch': int(np.argmin(val_losses) + 1),\n",
    "        'final_g_loss': float(train_losses_g[-1]),\n",
    "        'final_d_loss': float(train_losses_d[-1]),\n",
    "    },\n",
    "    'configuration': {\n",
    "        'batch_size': BATCH_SIZE,\n",
    "        'patch_size': list(PATCH_SIZE),\n",
    "        'train_subjects': train_subjects,\n",
    "        'val_subjects': val_subjects,\n",
    "        'test_subjects': test_subjects,\n",
    "        'modality': MODALITIES,\n",
    "    },\n",
    "    'created': datetime.now().isoformat(),\n",
    "}\n",
    "\n",
    "metrics_path = DIRS['logs'] / 'metrics_summary.json'\n",
    "with open(metrics_path, 'w') as f:\n",
    "    json.dump(metrics_summary, f, indent=2)\n",
    "\n",
    "print(f\"\\n‚úì Metrics saved to: {metrics_path.name}\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80b5582b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CELL 15: Create Final Output Package\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"PACKAGING OUTPUTS FOR DOWNLOAD\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "import shutil\n",
    "\n",
    "# Create final output directory\n",
    "final_dir = DIRS['final_output']\n",
    "final_dir.mkdir(exist_ok=True)\n",
    "\n",
    "print(\"üì¶ Copying files to final output directory...\\n\")\n",
    "\n",
    "# 1. Copy best model\n",
    "shutil.copy(\n",
    "    DIRS['checkpoints'] / 'best_model.pth',\n",
    "    final_dir / 'best_generator.pth'\n",
    ")\n",
    "print(\"‚úì Copied: best_generator.pth\")\n",
    "\n",
    "# 2. Copy training curves\n",
    "shutil.copy(\n",
    "    DIRS['logs'] / 'training_curves.png',\n",
    "    final_dir / 'training_curves.png'\n",
    ")\n",
    "print(\"‚úì Copied: training_curves.png\")\n",
    "\n",
    "# 3. Copy metrics\n",
    "shutil.copy(\n",
    "    DIRS['logs'] / 'metrics_summary.json',\n",
    "    final_dir / 'metrics_summary.json'\n",
    ")\n",
    "print(\"‚úì Copied: metrics_summary.json\")\n",
    "\n",
    "# 4. Copy data split\n",
    "shutil.copy(\n",
    "    DIRS['cache'] / 'data_split.json',\n",
    "    final_dir / 'data_split.json'\n",
    ")\n",
    "print(\"‚úì Copied: data_split.json\")\n",
    "\n",
    "# 5. Copy visualizations\n",
    "vis_dest = final_dir / 'visualizations'\n",
    "if vis_dest.exists():\n",
    "    shutil.rmtree(vis_dest)\n",
    "shutil.copytree(DIRS['visualizations'], vis_dest)\n",
    "print(f\"‚úì Copied: visualizations/ ({len(list(vis_dest.glob('*.png')))} files)\")\n",
    "\n",
    "# 6. Create README\n",
    "readme_content = f\"\"\"# Topo-Brain GAN Training Results\n",
    "\n",
    "**Generated on:** {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n",
    "\n",
    "## Training Summary\n",
    "\n",
    "### Configuration\n",
    "- **Epochs:** {NUM_EPOCHS}\n",
    "- **Batch Size:** {BATCH_SIZE}\n",
    "- **Patch Size:** {PATCH_SIZE}\n",
    "- **Modality:** {MODALITIES}\n",
    "- **Device:** {device}\n",
    "\n",
    "### Data Splits\n",
    "- **Train:** {len(train_subjects)} subjects ({len(train_pairs)} pairs)\n",
    "- **Validation:** {len(val_subjects)} subjects ({len(val_pairs)} pairs)\n",
    "- **Test:** {len(test_subjects)} subjects ({len(test_pairs)} pairs)\n",
    "\n",
    "### Training Subjects\n",
    "{train_subjects}\n",
    "\n",
    "### Validation Subjects\n",
    "{val_subjects}\n",
    "\n",
    "### Test Subjects\n",
    "{test_subjects}\n",
    "\n",
    "## Results\n",
    "\n",
    "### Training Performance\n",
    "- **Best Validation Loss:** {best_val_loss:.4f}\n",
    "- **Best Epoch:** {np.argmin(val_losses) + 1}\n",
    "- **Final Generator Loss:** {train_losses_g[-1]:.4f}\n",
    "- **Final Discriminator Loss:** {train_losses_d[-1]:.4f}\n",
    "\n",
    "### Quantitative Metrics (Validation Set)\n",
    "- **PSNR:** {psnr_mean:.2f} ¬± {psnr_std:.2f} dB\n",
    "- **SSIM:** {ssim_mean:.4f} ¬± {ssim_std:.4f}\n",
    "\n",
    "### Interpretation\n",
    "- **PSNR > 25 dB:** Good quality reconstruction\n",
    "- **SSIM > 0.85:** High structural similarity\n",
    "- Current results: {\"‚úÖ Good\" if psnr_mean > 25 and ssim_mean > 0.85 else \"‚ö†Ô∏è Needs improvement\"}\n",
    "\n",
    "## Files Included\n",
    "\n",
    "1. **best_generator.pth** - Trained generator weights (load with PyTorch)\n",
    "2. **training_curves.png** - Loss plots over training\n",
    "3. **metrics_summary.json** - Detailed quantitative metrics\n",
    "4. **data_split.json** - Train/val/test split information\n",
    "5. **visualizations/** - Sample generated 7T images\n",
    "6. **README.md** - This file\n",
    "\n",
    "## Usage\n",
    "\n",
    "### Loading the Model\n",
    "\n",
    "```python\n",
    "import torch\n",
    "from models.generator_unet3d import UNet3DGenerator\n",
    "\n",
    "# Create model\n",
    "generator = UNet3DGenerator()\n",
    "\n",
    "# Load weights\n",
    "checkpoint = torch.load('best_generator.pth')\n",
    "generator.load_state_dict(checkpoint['generator_state_dict'])\n",
    "generator.eval()\n",
    "\n",
    "# Use for inference\n",
    "with torch.no_grad():\n",
    "    generated_7t = generator(input_3t)\n",
    "```\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "1. **Evaluate on test set** - Use test subjects for final validation\n",
    "2. **Full volume inference** - Generate complete 7T volumes (not just patches)\n",
    "3. **Clinical validation** - Assess with radiologist review\n",
    "4. **Topology loss** - Add persistent homology loss for better anatomy preservation\n",
    "5. **Self-supervised pretraining** - Use ADNI dataset for improved generalization\n",
    "\n",
    "## Citation\n",
    "\n",
    "If you use this model, please cite:\n",
    "\n",
    "```\n",
    "@misc{{topobrain2025,\n",
    "  author = {{Your Name}},\n",
    "  title = {{Topo-Brain: Topology-Preserving 3T-to-7T MRI Super-Resolution}},\n",
    "  year = {{2025}},\n",
    "  publisher = {{GitHub}},\n",
    "  url = {{https://github.com/prabeshx12/Topo-Brain}}\n",
    "}}\n",
    "```\n",
    "\n",
    "## Contact\n",
    "\n",
    "For questions or issues, please open an issue on GitHub:\n",
    "https://github.com/prabeshx12/Topo-Brain\n",
    "\n",
    "---\n",
    "\n",
    "**Training completed successfully! üéâ**\n",
    "\"\"\"\n",
    "\n",
    "with open(final_dir / 'README.md', 'w') as f:\n",
    "    f.write(readme_content)\n",
    "print(\"‚úì Created: README.md\")\n",
    "\n",
    "# Create archive for easy download\n",
    "print(f\"\\nüì¶ Creating archive...\")\n",
    "archive_name = f\"topobrain_gan_results_{datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
    "\n",
    "os.chdir(BASE_DIR)\n",
    "!zip -r {archive_name}.zip gan_final_output/\n",
    "\n",
    "archive_path = BASE_DIR / f\"{archive_name}.zip\"\n",
    "if archive_path.exists():\n",
    "    size_mb = archive_path.stat().st_size / (1024**2)\n",
    "    print(f\"\\n‚úì Archive created: {archive_name}.zip ({size_mb:.1f} MB)\")\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"üì• DOWNLOAD FILES:\")\n",
    "print(f\"{'='*70}\")\n",
    "print(f\"\\n1. Single archive (recommended):\")\n",
    "print(f\"   üì¶ {archive_name}.zip\")\n",
    "print(f\"\\n2. Individual files from gan_final_output/:\")\n",
    "print(f\"   üìÑ best_generator.pth\")\n",
    "print(f\"   üìÑ training_curves.png\")\n",
    "print(f\"   üìÑ metrics_summary.json\")\n",
    "print(f\"   üìÑ data_split.json\")\n",
    "print(f\"   üìÅ visualizations/\")\n",
    "print(f\"   üìÑ README.md\")\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"‚úÖ ALL OUTPUTS PACKAGED AND READY!\")\n",
    "print(f\"{'='*70}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad693ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CELL 16: Final Summary and Next Steps\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üéâ GAN TRAINING COMPLETE!\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\\nüìä FINAL SUMMARY:\")\n",
    "print(f\"   ‚Ä¢ Total training time: {(time.time() - start_time)/3600:.2f} hours\")\n",
    "print(f\"   ‚Ä¢ Epochs completed: {NUM_EPOCHS}\")\n",
    "print(f\"   ‚Ä¢ Best validation loss: {best_val_loss:.4f}\")\n",
    "print(f\"   ‚Ä¢ PSNR: {psnr_mean:.2f} ¬± {psnr_std:.2f} dB\")\n",
    "print(f\"   ‚Ä¢ SSIM: {ssim_mean:.4f} ¬± {ssim_std:.4f}\")\n",
    "\n",
    "print(f\"\\nüìÅ OUTPUT LOCATIONS:\")\n",
    "print(f\"   ‚Ä¢ Checkpoints: {DIRS['checkpoints']}\")\n",
    "print(f\"   ‚Ä¢ Visualizations: {DIRS['visualizations']}\")\n",
    "print(f\"   ‚Ä¢ Logs: {DIRS['logs']}\")\n",
    "print(f\"   ‚Ä¢ Final package: {DIRS['final_output']}\")\n",
    "\n",
    "print(f\"\\nüéØ RECOMMENDED NEXT STEPS:\")\n",
    "print(f\"\\n   1. EVALUATE ON TEST SET\")\n",
    "print(f\"      ‚Üí Use held-out test subjects: {test_subjects}\")\n",
    "print(f\"      ‚Üí Compute metrics on unseen data\")\n",
    "print(f\"      ‚Üí Validate generalization\")\n",
    "\n",
    "print(f\"\\n   2. FULL VOLUME INFERENCE\")\n",
    "print(f\"      ‚Üí Generate complete 7T volumes (not just patches)\")\n",
    "print(f\"      ‚Üí Use sliding window with overlap\")\n",
    "print(f\"      ‚Üí Save as NIfTI for clinical review\")\n",
    "\n",
    "print(f\"\\n   3. ADD TOPOLOGY PRESERVATION\")\n",
    "print(f\"      ‚Üí Implement persistent homology loss\")\n",
    "print(f\"      ‚Üí Preserve anatomical connectivity\")\n",
    "print(f\"      ‚Üí Critical for Alzheimer's hippocampal analysis\")\n",
    "\n",
    "print(f\"\\n   4. SELF-SUPERVISED PRETRAINING\")\n",
    "print(f\"      ‚Üí Download ADNI Alzheimer's dataset\")\n",
    "print(f\"      ‚Üí Pretrain on large 3T cohort\")\n",
    "print(f\"      ‚Üí Fine-tune on paired 3T-7T data\")\n",
    "\n",
    "print(f\"\\n   5. CLINICAL VALIDATION\")\n",
    "print(f\"      ‚Üí Hippocampal volume measurement\")\n",
    "print(f\"      ‚Üí Cortical thickness analysis\")\n",
    "print(f\"      ‚Üí Radiologist quality assessment\")\n",
    "\n",
    "print(f\"\\nüìö REFERENCES:\")\n",
    "print(f\"   ‚Ä¢ Repository: https://github.com/prabeshx12/Topo-Brain\")\n",
    "print(f\"   ‚Ä¢ ADNI dataset: https://adni.loni.usc.edu/\")\n",
    "print(f\"   ‚Ä¢ UNC 3T-7T dataset: (your current data)\")\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"Thank you for using Topo-Brain!\")\n",
    "print(\"For questions: https://github.com/prabeshx12/Topo-Brain/issues\")\n",
    "print(\"=\"*70)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
