# Topo-Brain: 3Tâ†’7T MRI Super-Resolution with GANs

A complete pipeline for MRI preprocessing and 3T-to-7T super-resolution using 3D U-Net GANs. Includes brain extraction, preprocessing, and GAN training for generating high-field MRI images from low-field scans.

## ğŸ¯ Features

### Preprocessing Pipeline
- **HD-BET Brain Extraction**: Deep learning-based skull stripping
- **N4 Bias Field Correction**: Optional intensity non-uniformity correction
- **Spatial Normalization**: RAS+ reorientation, isotropic resampling
- **Intensity Normalization**: Z-score, min-max, or percentile methods
- **Quality Control**: Automated QC metrics and outlier detection

### GAN Architecture (3Tâ†’7T Super-Resolution)
- **3D U-Net Generator**: 5-level encoder-decoder with skip connections
- **3D PatchGAN Discriminator**: Multi-scale adversarial training
- **Paired Dataset**: Aligned 3T-7T pairs for supervised learning
- **Patient-Level Splits**: No data leakage between train/val/test
- **Advanced Augmentation**: MRI-specific augmentations (rotation, intensity, Gibbs ringing)

### Production Features
- **Deterministic & Reproducible**: Fixed random seeds, saved splits
- **Config-Driven**: Flexible configuration with multiple presets
- **TensorBoard Integration**: Real-time training monitoring
- **Mixed Precision Support**: AMP for faster training
- **Kaggle/Colab Ready**: Cloud preprocessing notebook included

## ğŸ“Š Dataset Structure

Your dataset follows the BIDS format:
- **10 subjects** (sub-01 to sub-10)
- **2 sessions per subject**:
  - `ses-1`: 3T scans
  - `ses-2`: 7T scans (~7T)
- **Modalities**: T1w and T2w

## ğŸ“ Project Structure

```
Topo-Brain/
â”œâ”€â”€ README.md                              # This file
â”œâ”€â”€ requirements.txt                       # Python dependencies
â”œâ”€â”€ kaggle_preprocessing_notebook.ipynb    # Cloud preprocessing
â”‚
â”œâ”€â”€ docs/                                  # ğŸ“š Documentation
â”‚   â”œâ”€â”€ ARCHITECTURE.md                    # System architecture
â”‚   â”œâ”€â”€ CHANGELOG.md                       # Version history
â”‚   â”œâ”€â”€ GAN_IMPLEMENTATION_SUMMARY.md      # GAN details
â”‚   â”œâ”€â”€ GAN_README.md                      # GAN documentation
â”‚   â””â”€â”€ IMPROVEMENTS_IMPLEMENTED.md        # Enhancement log
â”‚
â”œâ”€â”€ src/                                   # ğŸ Core modules
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                          # Configuration management
â”‚   â”œâ”€â”€ preprocessing.py                   # Preprocessing pipeline
â”‚   â”œâ”€â”€ dataset.py                         # PyTorch Dataset classes
â”‚   â”œâ”€â”€ utils.py                           # Utility functions
â”‚   â”œâ”€â”€ harmonization.py                   # Intensity harmonization
â”‚   â””â”€â”€ quality_control.py                 # QC metrics & reports
â”‚
â”œâ”€â”€ models/                                # ğŸ§  GAN models
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ generator_unet3d.py                # 3D U-Net generator
â”‚   â”œâ”€â”€ discriminator_patchgan3d.py        # PatchGAN discriminator
â”‚   â””â”€â”€ paired_dataset.py                  # 3T-7T paired dataset
â”‚
â”œâ”€â”€ scripts/                               # ğŸ”§ Executable scripts
â”‚   â”œâ”€â”€ generate_brain_masks.py            # HD-BET brain extraction
â”‚   â”œâ”€â”€ train_gan.py                       # GAN training script
â”‚   â”œâ”€â”€ eval_gan.py                        # GAN evaluation
â”‚   â”œâ”€â”€ test_gan.py                        # Model testing
â”‚   â””â”€â”€ example_pipeline.py                # Pipeline demo
â”‚
â”œâ”€â”€ notebooks/                             # ğŸ““ Jupyter notebooks
â”‚   â””â”€â”€ interactive_pipeline.ipynb         # Interactive demo
â”‚
â””â”€â”€ tests/                                 # âœ… Unit tests
    â””â”€â”€ __init__.py
```

## ğŸš€ Quick Start

### 1. Installation

```bash
# Clone repository
git clone https://github.com/prabeshx12/Topo-Brain.git
cd Topo-Brain

# Create virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt

# Install HD-BET for brain extraction
pip install HD-BET
```

### 2. Preprocessing Pipeline

#### Generate Brain Masks
```bash
python scripts/generate_brain_masks.py \
    --method hd-bet \
    --device cuda \
    --mode accurate \
    --data-root Nifti/
```

#### Preprocess MRI Data
```python
from src.config import get_default_config
from src.preprocessing import MRIPreprocessor
from src.utils import discover_dataset

# Load configuration
config = get_default_config()

# Discover dataset
data_list = discover_dataset(config.data.data_root, config.data)

# Preprocess
preprocessor = MRIPreprocessor(config.preprocessing)
for item in data_list:
    preprocessor.preprocess_single(
        item['path'],
        output_dir=config.data.output_root
    )
```

### 3. GAN Training (3Tâ†’7T Super-Resolution)

#### Create Dataset Splits
```python
from src.utils import create_patient_level_split
from models.paired_dataset import create_paired_data_list

# Patient-level split (no data leakage!)
train_data, val_data, test_data = create_patient_level_split(
    data_list,
    train_ratio=0.6,
    val_ratio=0.2,
    test_ratio=0.2,
    random_seed=42,
)

# Create 3Tâ†’7T pairs
train_pairs = create_paired_data_list(train_data, modality="T1w")
```

#### Train GAN
```bash
python scripts/train_gan.py \
    --data-root preprocessed/ \
    --output-dir checkpoints/baseline \
    --num-epochs 100 \
    --batch-size 2 \
    --patch-size 64 64 64 \
    --lambda-l1 100.0
```

#### Monitor Training
```bash
tensorboard --logdir checkpoints/baseline/logs
```

### 4. Evaluation
```bash
python scripts/eval_gan.py \
    --checkpoint checkpoints/baseline/best_generator.pth \
    --test-data preprocessed/ \
    --output-dir results/
```

## âš™ï¸ Configuration

### Configuration Presets

```python
from src.config import get_default_config, get_highres_config, get_fast_config

# Default: No resampling, z-score norm, N4 disabled (preserves detail)
config = get_default_config()

# High-res: 0.5mm isotropic, 256Â³ volumes
config = get_highres_config()

# Fast: 2.0mm isotropic, 96Â³ volumes (for prototyping)
config = get_fast_config()
```

### Custom Configuration
```python
from src.config import MRIConfig

config = MRIConfig()

# Preprocessing
config.preprocessing.target_spacing = (1.0, 1.0, 1.0)
config.preprocessing.normalization_method = "zscore"
config.preprocessing.use_bias_correction = False  # Preserves anatomical detail

# Customize splits
config.split.train_ratio = 0.7
config.split.val_ratio = 0.15
config.split.test_ratio = 0.15

# Customize training
config.training.batch_size = 4
config.training.num_workers = 8

config.validate()
```

## ğŸ”¬ Pipeline Details

### HD-BET Brain Extraction
- Deep learning-based skull stripping (nnU-Net architecture)
- Automatic model download (~100MB from Zenodo)
- GPU acceleration supported
- Modes: `fast`, `accurate`

### Preprocessing Steps
1. **Brain Extraction**: HD-BET for accurate skull stripping
2. **Bias Field Correction**: Optional N4ITK (disabled by default to preserve detail)
3. **Spatial Transforms**: RAS+ reorientation, optional resampling
4. **Intensity Normalization**: Z-score (recommended for GANs)

### GAN Architecture
- **Generator**: 3D U-Net with 5 levels, skip connections
- **Discriminator**: 3D PatchGAN (70Ã—70Ã—70 receptive field)
- **Loss**: L1 + Adversarial (Î»_L1 = 100)
- **Training**: Adam optimizer, Î²1=0.5, Î²2=0.999
- **Input**: 64Â³ patches from 3T MRI
- **Output**: 64Â³ synthetic 7T MRI

## ï¿½ Data Augmentation

### Training Augmentation (GAN)
- Random 3D affine transforms (rotation, translation, scaling)
- Random flipping (L-R, A-P, S-I)
- Random intensity shifts and scaling
- Random Gaussian noise
- Random Gaussian blur
- Optional: Gibbs ringing simulation

All configurable in [`models/paired_dataset.py`](models/paired_dataset.py)

## ğŸ¯ Patient-Level Splitting

**Critical for medical imaging**: Ensures no data leakage!

```python
# All sessions from the same patient go to the same split
train_subjects = ['sub-01', 'sub-02', 'sub-03', 'sub-04', 'sub-05', 'sub-06']
val_subjects = ['sub-07', 'sub-08']
test_subjects = ['sub-09', 'sub-10']

# This means both ses-1 AND ses-2 from sub-01 are in training set
```

The split is:
- **Deterministic**: Same random seed = same split
- **Saved**: JSON file for reproducibility
- **Verified**: Automatic leakage detection

## ğŸ“Š Dataset Statistics

The pipeline automatically computes and logs:
- Mean and standard deviation
- Min/max values
- Percentiles (1st, 99th)
- Median
- Shape distributions

Example output:
```
Dataset statistics:
  mean: 0.0234
  std: 0.9876
  min: -3.4567
  max: 4.5678
  median: 0.0123
```

## ğŸ–¼ï¸ Visualization

Automatic visualization of:
- Preprocessing verification (before/after comparison)
- Sample batches from train/val/test sets
- Intensity distributions
- Orthogonal slices (sagittal, coronal, axial)

Saved to `logs/visualizations/`

## ğŸ”§ Advanced Usage

### Multi-Modal Learning
```python
from dataset import MultiModalBrainMRIDataset

# Load T1w and T2w together
dataset = MultiModalBrainMRIDataset(
    data_list,
    modalities=["T1w", "T2w"],
    transform=transform,
)

# Each sample will have shape: (2, H, W, D)
```

### K-Fold Cross-Validation
```python
from utils import create_kfold_splits

folds = create_kfold_splits(data_list, k_folds=5, random_seed=42)

for fold_idx, (train_data, val_data) in enumerate(folds):
    print(f"Fold {fold_idx + 1}")
    # Train your model...
```

### Custom Transforms
```python
from monai.transforms import Compose, RandRotated

custom_transform = Compose([
    RandRotated(keys=["image"], range_x=0.5, prob=0.5),
    # Add your custom transforms...
])

dataset = BrainMRIDataset(data_list, transform=custom_transform)
```

## ğŸ“ File Outputs

```
preprocessed/                          # Preprocessed volumes
  â”œâ”€â”€ sub-01_ses-1_T1w_preprocessed.nii.gz
  â”œâ”€â”€ sub-01_ses-1_T1w_preprocessed_metadata.json
  â””â”€â”€ ...

checkpoints/                           # GAN training checkpoints
  â”œâ”€â”€ baseline/
  â”‚   â”œâ”€â”€ generator_epoch_50.pth
  â”‚   â”œâ”€â”€ discriminator_epoch_50.pth
  â”‚   â”œâ”€â”€ best_generator.pth
  â”‚   â””â”€â”€ logs/                        # TensorBoard logs

results/                               # Evaluation outputs
  â”œâ”€â”€ generated_7T/
  â”œâ”€â”€ metrics.json
  â””â”€â”€ visualizations/

cache/
  â””â”€â”€ data_split.json                  # Reproducible splits

logs/
  â”œâ”€â”€ pipeline.log
  â””â”€â”€ qc_reports/
```

## âš ï¸ Important Notes

### HD-BET Installation
```bash
# Install HD-BET for brain extraction
pip install HD-BET

# Models auto-download on first use (~100MB)
```

### N4 Bias Correction
- **Disabled by default** to preserve anatomical detail
- GANs can learn to handle bias fields
- Enable if needed: `config.preprocessing.use_bias_correction = True`

### Memory Requirements
- **GPU**: 8GB+ VRAM recommended for training (batch_size=2, patch=64Â³)
- **RAM**: 16GB+ for data loading
- Adjust batch size and patch size based on available memory

### Kaggle/Colab Usage
Use [`kaggle_preprocessing_notebook.ipynb`](kaggle_preprocessing_notebook.ipynb) for cloud preprocessing with free GPU

### Determinism
For full reproducibility:
```python
from utils import set_random_seeds
set_random_seeds(42)  # Sets seeds for random, numpy, torch
```

## ğŸ› Troubleshooting

### GPU Out of Memory
```python
# Reduce batch size
python scripts/train_gan.py --batch-size 1

# Reduce patch size
python scripts/train_gan.py --patch-size 32 32 32

# Use CPU (slow but works)
python scripts/train_gan.py --device cpu
```

### Import Errors After Reorganization
```python
# Use new import paths
from src.config import get_default_config  # âœ…
from config import get_default_config       # âŒ Old path
```

### HD-BET Model Download Issues
```bash
# Manual download if auto-download fails
python -c "from HD_BET.checkpoint_download import maybe_download_parameters; maybe_download_parameters()"
```

## ğŸ“š Documentation

- [`docs/ARCHITECTURE.md`](docs/ARCHITECTURE.md) - System architecture overview
- [`docs/GAN_README.md`](docs/GAN_README.md) - GAN model details
- [`docs/GAN_IMPLEMENTATION_SUMMARY.md`](docs/GAN_IMPLEMENTATION_SUMMARY.md) - Implementation notes
- [`docs/IMPROVEMENTS_IMPLEMENTED.md`](docs/IMPROVEMENTS_IMPLEMENTED.md) - Enhancement log

## ğŸ”— References

- **MONAI**: https://monai.io/
- **HD-BET**: https://github.com/MIC-DKFZ/HD-BET
- **Pix2Pix**: Isola et al. (2017) - Image-to-Image Translation with Conditional Adversarial Networks
- **3D U-Net**: Ã‡iÃ§ek et al. (2016) - 3D U-Net: Learning Dense Volumetric Segmentation
- **BIDS Format**: https://bids.neuroimaging.io/

## ğŸ“„ License

MIT License - See LICENSE file for details

## âœ¨ Citation

If you use this code, please cite:
```bibtex
@software{topo_brain_2025,
  author = {Your Name},
  title = {Topo-Brain: 3T-to-7T MRI Super-Resolution with GANs},
  year = {2025},
  url = {https://github.com/prabeshx12/Topo-Brain}
}
```

---

**Dataset**: UNC Paired 3T-7T MRI Dataset  
**Interactive Demo**: [`notebooks/interactive_pipeline.ipynb`](notebooks/interactive_pipeline.ipynb)  
**Cloud Processing**: [`kaggle_preprocessing_notebook.ipynb`](kaggle_preprocessing_notebook.ipynb)
